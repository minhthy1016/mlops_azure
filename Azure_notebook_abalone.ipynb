{"cells":[{"cell_type":"markdown","source":["**Import packages**"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"E8ivR-UwrM4T"}},{"cell_type":"code","source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import azureml.core\n","from azureml.core import Workspace\n","\n","# check core SDK version number\n","print(\"Azure ML SDK Version: \", azureml.core.VERSION)"],"outputs":[{"output_type":"stream","name":"stdout","text":"Azure ML SDK Version:  1.44.0\n"}],"execution_count":null,"metadata":{"gather":{"logged":1667571440002},"id":"fD8gfgJRrM4Y","outputId":"8963dd7a-1d12-4b10-82b1-bbb01b83c296"}},{"cell_type":"markdown","source":["**Connect to workspace**"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"X2nji4TJrM4a"}},{"cell_type":"code","source":["# load workspace configuration from the config.json file in the current folder.\n","ws = Workspace.from_config()\n","print(ws.name, ws.location, ws.resource_group, sep='\\t')\n","# workspace = Workspace(subscription_id, resource_group, workspace_name)"],"outputs":[{"output_type":"stream","name":"stdout","text":"mlops_minhthy_4\tsoutheastasia\tmlops_minhthy_4\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571448499},"id":"KE6RJF-LrM4b","outputId":"5d093d82-e6d3-4345-c6e4-3f3aac72c05d"}},{"cell_type":"markdown","source":["**Create experiment**"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"Lfxs0V3arM4b"}},{"cell_type":"code","source":["experiment_name = 'Abalone'\n","\n","from azureml.core import Experiment\n","exp = Experiment(workspace=ws, name=experiment_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571462013},"id":"N-I1xtxUrM4c"}},{"cell_type":"markdown","source":["**Create or Attach existing compute resource**"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"EYB9caSjrM4c"}},{"cell_type":"code","source":["from azureml.core.compute import AmlCompute\n","from azureml.core.compute import ComputeTarget\n","import os\n","\n","# choose a name for your cluster\n","compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n","compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n","compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n","\n","# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n","vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n","\n","\n","if compute_name in ws.compute_targets:\n","    compute_target = ws.compute_targets[compute_name]\n","    if compute_target and type(compute_target) is AmlCompute:\n","        print(\"found compute target: \" + compute_name)\n","else:\n","    print(\"creating new compute target...\")\n","    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n","                                                                min_nodes = compute_min_nodes, \n","                                                                max_nodes = compute_max_nodes)\n","\n","    # create the cluster\n","    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n","    \n","    # can poll for a minimum number of nodes and for a specific timeout. \n","    # if no min node count is provided it will use the scale settings for the cluster\n","    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n","    \n","     # For a more detailed view of current AmlCompute status, use get_status()\n","    print(compute_target.get_status().serialize())"],"outputs":[{"output_type":"stream","name":"stdout","text":"found compute target: cpu-cluster\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571471572},"id":"6TiiOB8srM4c","outputId":"d0dc075d-1fda-4072-f680-65fcca81c18e"}},{"cell_type":"markdown","source":["Upload the Abalone dataset"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"R4aAWFuBrM4e"}},{"cell_type":"code","source":["from azureml.core import Dataset\n","# from azureml.opendatasets import MNIST\n","\n","\n","# azureml-core of version 1.0.72 or higher is required\n","# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n","from azureml.core import Workspace, Dataset\n","\n","\n","subscription_id = 'f548d18b-21f1-4160-b68c-b4577cad9721'\n","resource_group = 'Mlops_MinhThy_4'\n","workspace_name = 'Mlops_MinhThy_4'\n","\n","workspace = Workspace(subscription_id, resource_group, workspace_name)\n","\n","dataset = Dataset.get_by_name(workspace, name='abalone_age_new')\n","dataset.take(5).to_pandas_dataframe()"],"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n0   M  455.00    365.00   95.00       514.000           2.245         101.000   \n1   M    0.35    265.00    0.09         2.255         995.000         485.000   \n2   F    0.53      0.42  135.00       677.000           2.565           1.415   \n3   M    0.44    365.00  125.00       516.000           2.155         114.000   \n4   I    0.33    255.00    0.08       205.000         895.000         395.000   \n\n   Shell weight  Rings   Age  \n0          0.15     15  16,5  \n1          0.07      7   8,5  \n2          0.21      9  10,5  \n3        155.00     10  11,5  \n4         55.00      7   8,5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Shucked weight</th>\n      <th>Viscera weight</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>455.00</td>\n      <td>365.00</td>\n      <td>95.00</td>\n      <td>514.000</td>\n      <td>2.245</td>\n      <td>101.000</td>\n      <td>0.15</td>\n      <td>15</td>\n      <td>16,5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>0.35</td>\n      <td>265.00</td>\n      <td>0.09</td>\n      <td>2.255</td>\n      <td>995.000</td>\n      <td>485.000</td>\n      <td>0.07</td>\n      <td>7</td>\n      <td>8,5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>0.53</td>\n      <td>0.42</td>\n      <td>135.00</td>\n      <td>677.000</td>\n      <td>2.565</td>\n      <td>1.415</td>\n      <td>0.21</td>\n      <td>9</td>\n      <td>10,5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.44</td>\n      <td>365.00</td>\n      <td>125.00</td>\n      <td>516.000</td>\n      <td>2.155</td>\n      <td>114.000</td>\n      <td>155.00</td>\n      <td>10</td>\n      <td>11,5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.33</td>\n      <td>255.00</td>\n      <td>0.08</td>\n      <td>205.000</td>\n      <td>895.000</td>\n      <td>395.000</td>\n      <td>55.00</td>\n      <td>7</td>\n      <td>8,5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574392549},"id":"cx2jDb3CrM4e","outputId":"b269f367-1898-4d90-d4f7-161b6cafb9a9"}},{"cell_type":"markdown","source":["Download the dataset from file"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"iylAo5jSrM4f"}},{"cell_type":"code","source":["# azureml-core of version 1.0.72 or higher is required\n","from azureml.core import Workspace, Dataset\n","\n","subscription_id = 'f548d18b-21f1-4160-b68c-b4577cad9721'\n","resource_group = 'Mlops_MinhThy_4'\n","workspace_name = 'Mlops_MinhThy_4'\n","\n","workspace = Workspace(subscription_id, resource_group, workspace_name)\n","data_folder = os.path.join(os.getcwd(), 'data')\n","os.makedirs(data_folder, exist_ok=True)\n","\n","df = Dataset.get_by_name(workspace, name='abalone_1')\n","df.download(data_folder, overwrite=True)\n","\n","\n","abalone_file_dataset = df.register(workspace=ws,\n","                                    name='abalone_opendataset',\n","                                    description='training and test dataset',\n","                                    create_new_version=True)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571501975},"id":"ioUSW3v7rM4f"}},{"cell_type":"code","source":["import pandas as pd\n","dataset_age = pd.DataFrame([])\n","dataset['Age'].values = dataset['Rings'] +1.5\n","dataset_age = dataset.append(dataset['Age'].values)\n","dataset_age  \n","# dataset.to_pandas_dataframe()"],"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'TabularDataset' object has no attribute 'append'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_age \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([])\n\u001b[1;32m      3\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1.5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset_age \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      5\u001b[0m dataset_age\n","\u001b[0;31mAttributeError\u001b[0m: 'TabularDataset' object has no attribute 'append'"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667653778086},"id":"3OS1iTNqrM4g","outputId":"dba91479-6a30-4024-a890-7d048cec7f7b"}},{"cell_type":"markdown","source":["Create new or use an existing compute"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"w89KffYerM4g"}},{"cell_type":"code","source":["from azureml.core.compute import ComputeTarget, AmlCompute\n","from azureml.core.compute_target import ComputeTargetException\n","\n","amlcompute_cluster_name = \"n105962831\"\n","\n","# Verify that cluster does not exist already\n","try:\n","    aml_compute = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n","    print('Found existing cluster, use it.')\n","except ComputeTargetException:\n","    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n","                                                           max_nodes=4)\n","    aml_compute = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n","\n","aml_compute.wait_for_completion(show_output=True)"],"outputs":[{"output_type":"stream","name":"stdout","text":"Found existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571575161},"id":"NYH3mRiIrM4g","outputId":"4f004850-eb19-403b-cbec-3ee6857d6df4"}},{"cell_type":"code","source":["from azureml.core.runconfig import RunConfiguration, DockerConfiguration\n","from azureml.core.conda_dependencies import CondaDependencies\n","\n","# Create a new runconfig object\n","aml_run_config = RunConfiguration()\n","\n","# Use the aml_compute being created above. \n","aml_run_config.target = aml_compute\n","\n","# Enable Docker\n","docker=DockerConfiguration(use_docker=True)\n","aml_run_config.docker=docker\n","\n","# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n","aml_run_config.environment.python.user_managed_dependencies = False\n","\n","# Specify CondaDependencies obj, add necessary packages\n","aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n","    conda_packages=['pandas','scikit-learn'], \n","    pip_packages=['azureml-sdk[automl]', 'pyarrow'])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571597001},"id":"9GV8TrHerM4h"}},{"cell_type":"code","source":["#See our config\n","\n","aml_run_config.environment"],"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"{\n    \"assetId\": null,\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"buildContext\": null,\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": \"2g\"\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": null,\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.8.13\",\n                {\n                    \"pip\": [\n                        \"azureml-sdk[automl]~=1.44.0\",\n                        \"pyarrow\"\n                    ]\n                },\n                \"pandas\",\n                \"scikit-learn\"\n            ],\n            \"name\": \"project_environment\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": null\n}"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571604093},"id":"s5DcmOairM4i","outputId":"dd45f16a-e74b-439d-b17c-c66f13ec79d3"}},{"cell_type":"markdown","source":["Define useful Columns"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"ZudmClXYrM4i"}},{"cell_type":"code","source":["dataset.take(5).to_pandas_dataframe()"],"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n0   M  455.00    365.00   95.00       514.000           2.245         101.000   \n1   M    0.35    265.00    0.09         2.255         995.000         485.000   \n2   F    0.53      0.42  135.00       677.000           2.565           1.415   \n3   M    0.44    365.00  125.00       516.000           2.155         114.000   \n4   I    0.33    255.00    0.08       205.000         895.000         395.000   \n\n   Shell weight  Rings   Age  \n0          0.15     15  16,5  \n1          0.07      7   8,5  \n2          0.21      9  10,5  \n3        155.00     10  11,5  \n4         55.00      7   8,5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Shucked weight</th>\n      <th>Viscera weight</th>\n      <th>Shell weight</th>\n      <th>Rings</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>455.00</td>\n      <td>365.00</td>\n      <td>95.00</td>\n      <td>514.000</td>\n      <td>2.245</td>\n      <td>101.000</td>\n      <td>0.15</td>\n      <td>15</td>\n      <td>16,5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>0.35</td>\n      <td>265.00</td>\n      <td>0.09</td>\n      <td>2.255</td>\n      <td>995.000</td>\n      <td>485.000</td>\n      <td>0.07</td>\n      <td>7</td>\n      <td>8,5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>0.53</td>\n      <td>0.42</td>\n      <td>135.00</td>\n      <td>677.000</td>\n      <td>2.565</td>\n      <td>1.415</td>\n      <td>0.21</td>\n      <td>9</td>\n      <td>10,5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>0.44</td>\n      <td>365.00</td>\n      <td>125.00</td>\n      <td>516.000</td>\n      <td>2.155</td>\n      <td>114.000</td>\n      <td>155.00</td>\n      <td>10</td>\n      <td>11,5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I</td>\n      <td>0.33</td>\n      <td>255.00</td>\n      <td>0.08</td>\n      <td>205.000</td>\n      <td>895.000</td>\n      <td>395.000</td>\n      <td>55.00</td>\n      <td>7</td>\n      <td>8,5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574437349},"id":"BqaynpMCrM4i","outputId":"481b90b6-5717-4095-e62f-60b8bc17b725"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","\n","# useful columns\n","useful_columns = str(['Sex','Length','Diameter','Height',\n","                    'Whole weight','Shucked weight','Viscera weight','Shell weight','Rings','Age']).replace(\",\", \";\")\n","\n","print(\"Selected columns: \", useful_columns)"],"outputs":[{"output_type":"stream","name":"stdout","text":"Selected columns:  ['Sex'; 'Length'; 'Diameter'; 'Height'; 'Whole weight'; 'Shucked weight'; 'Viscera weight'; 'Shell weight'; 'Rings'; 'Age']\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574461092},"id":"NtSkUJgyrM4j","outputId":"1147f3f9-1e74-46cd-d862-5de7f770b3e8"}},{"cell_type":"markdown","source":["Createvfolder scripts_1/prepdata"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"yb8bXMzUrM4j"}},{"cell_type":"code","source":["os.mkdir(\"scripts_1/prepdata\")\n","%%writefile \"scripts_1/prepdata/cleanse.py\"\n","\n","import argparse\n","import os\n","from azureml.core import Run\n","\n","print(\"Clean the input data\")\n","\n","run = Run.get_context()\n","raw_data = run.input_datasets[\"raw_data\"]\n","\n","parser = argparse.ArgumentParser(\"cleanse\")\n","parser.add_argument(\"--output_cleanse\", type=str, help=\"cleaned abalone data directory\")\n","parser.add_argument(\"--useful_columns\", type=str, help=\"useful columns to keep\")\n","parser.add_argument(\"--columns\", type=str, help=\"rename column pattern\")\n","\n","args = parser.parse_args()\n","\n","print(\"Argument 1(columns to keep): %s\" % str(args.useful_columns.strip(\"[]\").split(r'\\;')))\n","print(\"Argument 2(columns renaming mapping): %s\" % str(args.columns.strip(\"{}\").split(r'\\;')))\n","print(\"Argument 3(output cleansed abalone data path): %s\" % args.output_cleanse)\n","\n","# These functions ensure that null data is removed from the dataset,\n","# which will help increase machine learning model accuracy.\n","\n","useful_columns = eval(args.useful_columns.replace(';', ','))\n","columns = eval(args.columns.replace(';', ','))\n","\n","new_df = (dataset.to_pandas_dataframe()\n","          .dropna(how='all')\n","          .rename(columns=columns))[useful_columns]\n","\n","new_df.reset_index(inplace=True, drop=True)\n","\n","if not (args.output_cleanse is None):\n","    os.makedirs(args.output_cleanse, exist_ok=True)\n","    print(\"%s created\" % args.output_cleanse)\n","    path = args.output_cleanse + \"/processed.parquet\"\n","    write_df = new_df.to_parquet(path)\n"],"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"[Errno 17] File exists: 'scripts_1/prepdata'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscripts_1/prepdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mwritefile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscripts_1/prepdata/cleanse.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'scripts_1/prepdata'"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667653778413},"id":"d_THvTt0rM4j","outputId":"57d623b3-bca3-4ba1-ad44-ab47ce3ed65c"}},{"cell_type":"code","source":["default_store = ws.get_default_datastore() "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667571669063},"id":"1_m70HQGrM4k"}},{"cell_type":"code","source":["from azureml.pipeline.core import PipelineData\n","from azureml.pipeline.steps import PythonScriptStep\n","\n","# python scripts folder\n","prepare_data_folder = './scripts_1/prepdata'\n","\n","\n","# rename columns \n","abalone_columns = str({ \n","    'Sex': \"sex\",\n","    'Length': \"length\",\n","    'Diameter': \"diameter\",\n","    'Height': \"height\",\n","    'Whole weight': \"whole_weight\",\n","    'Shucked weight': \"shucked_weight\",\n","    'Viscera weight': \"viscera_weight\",\n","    'Shell weight': \"shell_weight\",\n","    'Rings': \"rings\",\n","    'Age':'age'\n","}).replace(\",\", \";\")\n","\n","# Define output after cleansing step\n","cleansed_abalone_data = PipelineData(\"cleansed_abalone_data\", datastore=default_store).as_dataset()\n","\n","print('Cleanse script is in {}.'.format(os.path.realpath(prepare_data_folder)))\n","\n","# cleansing step creation\n","# See the cleanse.py for details about input and output\n","cleansingStep = PythonScriptStep(\n","    name=\"Cleanse abalone Data\",\n","    script_name=\"cleanse.py\", \n","    arguments=[\"--useful_columns\", useful_columns,\n","               \"--columns\", abalone_columns,\n","               \"--output_cleanse\", cleansed_abalone_data],\n","    inputs=[dataset.as_named_input('raw_data')],\n","    outputs=[cleansed_abalone_data],\n","    compute_target=aml_compute,\n","    runconfig=aml_run_config,\n","    source_directory=prepare_data_folder,\n","    allow_reuse=True\n",")\n","\n","print(\"cleansingStep created.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":"Cleanse script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops4/code/Users/minhthy1016/scripts_1/prepdata.\ncleansingStep created.\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574497752},"id":"AJuyu3FRrM4k","outputId":"69a83b57-a3ef-4bdc-9916-402e288db978"}},{"cell_type":"markdown","source":["Split the data into train and test sets"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"9EedacZNrM4l"}},{"cell_type":"code","source":["%%writefile \"scripts_1/prepdata/split_data.py\"\n","\n","import argparse\n","import os\n","# import azureml.core\n","from azureml.core import Run\n","from sklearn.model_selection import train_test_split\n","\n","\n","def write_output(df, path):\n","    os.makedirs(path, exist_ok=True)\n","    print(\"%s created\" % path)\n","    df.to_parquet(path + \"/processed.parquet\")\n","\n","\n","print(\"Split the data into train and test\")\n","run = Run.get_context()\n","transformed_data = run.input_datasets['transformed_data']\n","transformed_df = transformed_data.to_pandas_dataframe()\n","\n","parser = argparse.ArgumentParser(\"split\")\n","parser.add_argument(\"--output_split_train\", type=str, help=\"output split train data\")\n","parser.add_argument(\"--output_split_test\", type=str, help=\"output split test data\")\n","\n","args = parser.parse_args()\n","\n","print(\"Argument 1(output training data split path): %s\" % args.output_split_train)\n","print(\"Argument 2(output test data split path): %s\" % args.output_split_test)\n","\n","output_split_train, output_split_test = train_test_split(transformed_df, test_size=0.2, random_state=223)\n","output_split_train.reset_index(inplace=True, drop=True)\n","output_split_test.reset_index(inplace=True, drop=True)\n","\n","if not (args.output_split_train\n","        is None and args.output_split_test is None):\n","    write_output(output_split_train, args.output_split_train)\n","    write_output(output_split_test, args.output_split_test)"],"outputs":[{"output_type":"stream","name":"stdout","text":"Overwriting scripts_1/prepdata/split_data.py\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"lTyaE6r-rM4l","outputId":"9e0aa382-062d-407d-afaf-fb14f6248ace"}},{"cell_type":"code","source":["train_model_folder = './scripts_1/prepdata/'\n","\n","# train and test splits output\n","output_split_train = PipelineData(\"output_split_train\", datastore=default_store).as_dataset()\n","output_split_test = PipelineData(\"output_split_test\", datastore=default_store).as_dataset()\n","\n","print('Data spilt script is in {}.'.format(os.path.realpath(train_model_folder)))\n","\n","# test train split step creation\n","# See the train_test_split.py for details about input and output\n","testTrainSplitStep = PythonScriptStep(\n","    name=\"Train Test Data Split\",\n","    script_name=\"split_data.py\", \n","    arguments=[\"--output_split_train\", output_split_train,\n","               \"--output_split_test\", output_split_test],\n","    inputs=[dataset.as_named_input('raw_data')],\n","    outputs=[output_split_train, output_split_test],\n","    compute_target=aml_compute,\n","    runconfig = aml_run_config,\n","    source_directory=train_model_folder,\n","    allow_reuse=True\n",")\n","\n","print(\"testTrainSplitStep created.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":"Data spilt script is in /mnt/batch/tasks/shared/LS_root/mounts/clusters/mlops4/code/Users/minhthy1016/scripts_1/prepdata.\ntestTrainSplitStep created.\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574815121},"id":"E5x9gGYarM4l","outputId":"cd77bb0b-a954-45e6-d37a-50b534ac38f0"}},{"cell_type":"markdown","source":["Automatically train a model\n","Create Experiment"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"aa10nMZgrM4m"}},{"cell_type":"code","source":["from azureml.core import Experiment\n","\n","experiment = Experiment(ws, 'Abalone_Pipelines')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574845451},"id":"gwNCfjIWrM4m"}},{"cell_type":"markdown","source":["Define settings for autogeneration and tuning"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"rlhlOBB7rM4m"}},{"cell_type":"code","source":["from azureml.train.automl import AutoMLConfig\n","\n","# Change iterations to a reasonable number (50) to get better accuracy\n","automl_settings = {\n","    \"iteration_timeout_minutes\" : 5,\n","    \"iterations\" : 2,\n","    \"primary_metric\" : 'spearman_correlation',\n","    \"n_cross_validations\": 5\n","}\n","\n","training_dataset = output_split_train.parse_parquet_files().keep_columns(['pickup_weekday','pickup_hour', 'distance','passengers', 'vendor', 'cost'])\n","\n","automl_config = AutoMLConfig(task = 'regression',\n","                             debug_log = 'automated_ml_errors.log',\n","                             path = train_model_folder,\n","                             compute_target = aml_compute,\n","                             featurization = 'auto',\n","                             training_data = training_dataset,\n","                             label_column_name = 'cost',\n","                             **automl_settings)\n","                             "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574923666},"id":"0FGkuQyzrM4n"}},{"cell_type":"markdown","source":["Define AutoMLStep"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"1skjexH-rM4n"}},{"cell_type":"code","source":["from azureml.pipeline.steps import AutoMLStep\n","\n","trainWithAutomlStep = AutoMLStep(name='AutoML_Regression',\n","                                 automl_config=automl_config,\n","                                 allow_reuse=True)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574957464},"id":"L5gBa1UVrM4n"}},{"cell_type":"markdown","source":["Build and run the pipeline"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"NUojCkNlrM4n"}},{"cell_type":"code","source":["from azureml.pipeline.core import Pipeline\n","from azureml.widgets import RunDetails\n","\n","pipeline_steps = [trainWithAutomlStep]\n","\n","pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n","\n","pipeline_run = experiment.submit(pipeline, regenerate_outputs=False)\n","\n"],"outputs":[{"output_type":"stream","name":"stdout","text":"Created step AutoML_Regression [766db0a2][5d40244e-e80d-495c-b1a6-c6799f355490], (This step will run and generate new outputs)\nCreated step Train Test Data Split [6269c344][aaf56703-8ddd-43fe-bd76-cadbfcf119fa], (This step will run and generate new outputs)\nSubmitted PipelineRun ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21?wsid=/subscriptions/f548d18b-21f1-4160-b68c-b4577cad9721/resourcegroups/mlops_minhthy_4/workspaces/mlops_minhthy_4&tid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667574997349},"id":"J-iKg6a6rM4n","outputId":"29505de7-7f5a-4f1c-c151-e6cef5761bd5"}},{"cell_type":"code","source":["RunDetails(pipeline_run).show()"],"outputs":[{"output_type":"display_data","data":{"text/plain":"_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c02d70bf66ab48f3af6961c767f3dc2c"}},"metadata":{}},{"output_type":"display_data","data":{"application/aml.mini.widget.v1":"{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21?wsid=/subscriptions/f548d18b-21f1-4160-b68c-b4577cad9721/resourcegroups/mlops_minhthy_4/workspaces/mlops_minhthy_4&tid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92\", \"run_id\": \"ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21\", \"run_properties\": {\"run_id\": \"ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21\", \"created_utc\": \"2022-11-04T15:16:36.056025Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlops4.blob.core.windows.net/azureml/ExperimentRun/dcid.ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=S%2FeS5pokT2%2B6gJDGBgFhp7Htf6Z7KkPnIH6JUYn20zY%3D&skoid=624963e0-b981-40f6-bbdc-c3d516078e2f&sktid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92&skt=2022-11-04T15%3A06%3A38Z&ske=2022-11-05T23%3A16%3A38Z&sks=b&skv=2019-07-07&st=2022-11-04T16%3A57%3A47Z&se=2022-11-05T01%3A07%3A47Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlops4.blob.core.windows.net/azureml/ExperimentRun/dcid.ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=GLYMRxM0%2BMLSEncDnJWlO7tnFZFoVJWar%2BeN3iAV9XI%3D&skoid=624963e0-b981-40f6-bbdc-c3d516078e2f&sktid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92&skt=2022-11-04T15%3A06%3A38Z&ske=2022-11-05T23%3A16%3A38Z&sks=b&skv=2019-07-07&st=2022-11-04T16%3A57%3A47Z&se=2022-11-05T01%3A07%3A47Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlops4.blob.core.windows.net/azureml/ExperimentRun/dcid.ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=i%2Fnn12xaoRts36YY%2FHDmo3Y9PlI404B5WjhRR60bTZU%3D&skoid=624963e0-b981-40f6-bbdc-c3d516078e2f&sktid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92&skt=2022-11-04T15%3A06%3A38Z&ske=2022-11-05T23%3A16%3A38Z&sks=b&skv=2019-07-07&st=2022-11-04T16%3A57%3A47Z&se=2022-11-05T01%3A07%3A47Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"1:51:11\", \"run_number\": \"1667574996\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"\", \"name\": \"AutoML_Regression\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}, {\"run_id\": \"46ff8539-d29c-4f4d-9c85-0499ca2669fb\", \"name\": \"Train Test Data Split\", \"status\": \"Running\", \"start_time\": \"\", \"created_time\": \"2022-11-04T15:16:40.796723Z\", \"end_time\": \"\", \"duration\": \"1:51:07\", \"run_number\": 1667575000, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-11-04T15:16:40.796723Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-11-04 15:16:39Z] Submitting 1 runs, first five are: 6269c344:46ff8539-d29c-4f4d-9c85-0499ca2669fb\\n\", \"graph\": {\"datasource_nodes\": {\"2b1eb09f\": {\"node_id\": \"2b1eb09f\", \"name\": \"abalone_age_new\"}}, \"module_nodes\": {\"766db0a2\": {\"node_id\": \"766db0a2\", \"name\": \"AutoML_Regression\", \"status\": \"NotStarted\"}, \"6269c344\": {\"node_id\": \"6269c344\", \"name\": \"Train Test Data Split\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"46ff8539-d29c-4f4d-9c85-0499ca2669fb\"}}, \"edges\": [{\"source_node_id\": \"6269c344\", \"source_node_name\": \"Train Test Data Split\", \"source_name\": \"output_split_train\", \"target_name\": \"training_data\", \"dst_node_id\": \"766db0a2\", \"dst_node_name\": \"AutoML_Regression\"}, {\"source_node_id\": \"2b1eb09f\", \"source_node_name\": \"abalone_age_new\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"6269c344\", \"dst_node_name\": \"Train Test Data Split\"}], \"child_runs\": [{\"run_id\": \"\", \"name\": \"AutoML_Regression\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}, {\"run_id\": \"46ff8539-d29c-4f4d-9c85-0499ca2669fb\", \"name\": \"Train Test Data Split\", \"status\": \"Running\", \"start_time\": \"\", \"created_time\": \"2022-11-04T15:16:40.796723Z\", \"end_time\": \"\", \"duration\": \"1:51:07\", \"run_number\": 1667575000, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-11-04T15:16:40.796723Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667575040164},"colab":{"referenced_widgets":["c02d70bf66ab48f3af6961c767f3dc2c"]},"id":"6OpVOLrErM4o","outputId":"55e23c8b-792f-4ff2-e3ce-a7f99e327e53"}},{"cell_type":"markdown","source":["Explore the results"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"PmkR6WcGrM4o"}},{"cell_type":"code","source":["# Before we proceed we need to wait for the run to complete.\n","pipeline_run.wait_for_completion(show_output=False)\n","\n","# functions to download output to local and fetch as dataframe\n","def get_download_path(download_path, output_name):\n","    output_folder = os.listdir(download_path + '/azureml')[0]\n","    path =  download_path + '/azureml/' + output_folder + '/' + output_name\n","    return path\n","\n","def fetch_df(current_step, output_name):\n","    output_data = current_step.get_output_data(output_name)    \n","    download_path = './outputs/' + output_name\n","    output_data.download(download_path, overwrite=True)\n","    df_path = get_download_path(download_path, output_name) + '/processed.parquet'\n","    return pd.read_parquet(df_path)"],"outputs":[{"output_type":"stream","name":"stdout","text":"PipelineRunId: ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/ff45f7e5-4430-43e3-bdd2-e92cbd0a7d21?wsid=/subscriptions/f548d18b-21f1-4160-b68c-b4577cad9721/resourcegroups/mlops_minhthy_4/workspaces/mlops_minhthy_4&tid=f8a4d2e4-e0f0-4ff9-8809-bd26c493be92\n"}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667581705287},"id":"Q5PxIPDMrM4o","outputId":"32988e4b-3176-47d3-d6ec-6a6fd5b78c26"}},{"cell_type":"markdown","source":["View training data used by AutoML"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"JMWuXgVCrM4o"}},{"cell_type":"code","source":["split_step = pipeline_run.find_step_run(testTrainSplitStep.name)[0]\n","train_split = fetch_df(split_step, output_split_train.name)\n","\n","display(train_split.describe())\n","display(train_split.head(5))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"SjDZqWoHrM4y"}},{"cell_type":"markdown","source":["View test data used by AutoML"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"tGCINHkCrM4y"}},{"cell_type":"code","source":["split_step = pipeline_run.find_step_run(testTrainSplitStep.name)[0]\n","test_split = fetch_df(split_step, output_split_test.name)\n","\n","display(test_split.describe())\n","display(test_split.head(5))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"t-U3A0TJrM4y"}},{"cell_type":"markdown","source":["View the details of the AutoML run"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"CB2LusonrM4z"}},{"cell_type":"code","source":["from azureml.train.automl.run import AutoMLRun\n","#from azureml.widgets import RunDetails\n","\n","# workaround to get the automl run as its the last step in the pipeline \n","# and get_steps() returns the steps from latest to first\n","\n","for step in pipeline_run.get_steps():\n","    automl_step_run_id = step.id\n","    print(step.name)\n","    print(automl_step_run_id)\n","    break\n","\n","automl_run = AutoMLRun(experiment = experiment, run_id=automl_step_run_id)\n","#RunDetails(automl_run).show()\n","\n","RunDetails(automl_run).show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"BqhT3ZWYrM4z"}},{"cell_type":"markdown","source":["**Retrieve the best model**\n","\n","Select the best model from your iterations. The get_output function returns the best run and the fitted model for the last fit invocation. By using the overloads on get_output, you can retrieve the best run and fitted model for any logged metric or a particular iteration.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"1V8QYGdWrM4z"}},{"cell_type":"code","source":["best_run, fitted_model = automl_run.get_output()\n","print(best_run)\n","print(fitted_model)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"wpxDZr-DrM4z"}},{"cell_type":"markdown","source":["**Test the best model accuracy**\n","\n","Use the best model to run predictions on the test data set to predict taxi fares. The function predict uses the best model and predicts the values of y, trip cost, from the x_test data set. Print the first 10 predicted cost values from y_predict."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"ihkNY08crM40"}},{"cell_type":"code","source":["y_test = test_split.pop(\"Age\")\n","\n","y_predict = fitted_model.predict(test_split)\n","print(y_predict[:10])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"TteyHNtwrM40"}},{"cell_type":"markdown","source":["Calculate the root mean squared error of the results. Convert the y_test dataframe to a list to compare to the predicted values. The function mean_squared_error takes two arrays of values and calculates the average squared error between them. Taking the square root of the result gives an error in the same units as the y variable, cost. It indicates roughly how far the taxi fare predictions are from the actual fares."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"sG_UzFIsrM40"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","y_actual = y_test.values.flatten().tolist()\n","rmse = sqrt(mean_squared_error(y_actual, y_predict))\n","rmse"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"nRv7yk1UrM40"}},{"cell_type":"markdown","source":["Run the following code to calculate mean absolute percent error (MAPE) by using the full y_actual and y_predict data sets. This metric calculates an absolute difference between each predicted and actual value and sums all the differences. Then it expresses that sum as a percent of the total of the actual values."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"BG8UczeTrM41"}},{"cell_type":"code","source":["sum_actuals = sum_errors = 0\n","\n","for actual_val, predict_val in zip(y_actual, y_predict):\n","    abs_error = actual_val - predict_val\n","    if abs_error < 0:\n","        abs_error = abs_error * -1\n","\n","    sum_errors = sum_errors + abs_error\n","    sum_actuals = sum_actuals + actual_val\n","\n","mean_abs_percent_error = sum_errors / sum_actuals\n","print(\"Model MAPE:\")\n","print(mean_abs_percent_error)\n","print()\n","print(\"Model Accuracy:\")\n","print(1 - mean_abs_percent_error)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"QRdT4u1arM41"}},{"cell_type":"markdown","source":["*****Extra Part to consider ****"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"JsAAnGLzrM41"}},{"cell_type":"markdown","source":["Create a training script"],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"YbVq8tjirM41"}},{"cell_type":"code","source":["# %%writefile $scripts_1/train.py\n","%%writefile \"scripts_1/prepdata/train.py\"\n","\n","import argparse\n","import os\n","import numpy as np\n","import glob\n","\n","from sklearn.linear_model import LogisticRegression\n","import joblib\n","\n","from azureml.core import Run\n","from utils import load_data\n","from azureml.core import Run, Dataset\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","\n","# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n","parser.add_argument('--regularization', type=float, dest='reg', default=0.01, help='regularization rate')\n","args = parser.parse_args()\n","\n","data_folder = args.data_folder\n","print('Data folder:', data_folder)\n","\n","\n","# Set regularization hyperparameter (passed as an argument to the script)\n","reg = args.reg_rate\t\n","\n","# Get the experiment run context\n","run = Run.get_context()\n","\n","# Separate features and labels\n","X, y = dataset[['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight']].values, dataset['Age'].values\n","\n","# Split data into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n","\n","# Train a logistic regression model\n","print('Training a logistic regression model with regularization rate of', reg)\n","run.log('Regularization Rate',  np.float(reg))\n","model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n","\n","# calculate accuracy\n","y_hat = model.predict(X_test)\n","acc = np.average(y_hat == y_test)\n","print('Accuracy:', acc)\n","run.log('Accuracy', np.float(acc))\n","\n","# calculate AUC\n","y_scores = model.predict_proba(X_test)\n","auc = roc_auc_score(y_test,y_scores[:,1])\n","print('AUC: ' + str(auc))\n","\n","\n","os.makedirs('outputs', exist_ok=True)\n","# note file saved in the outputs folder is automatically uploaded into experiment record\n","joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n","\n","run.complete()\n","\n","\n"],"outputs":[{"output_type":"stream","name":"stdout","text":"Writing $scripts_1/train.py\n"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '$scripts_1/train.py'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwritefile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$scripts_1/train.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport argparse\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport os\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport numpy as np\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport glob\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.linear_model import LogisticRegression\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport joblib\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom azureml.core import Run\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom utils import load_data\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom azureml.core import Run, Dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport pandas as pd\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport numpy as np\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.model_selection import train_test_split\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.linear_model import LogisticRegression\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.metrics import roc_auc_score\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.metrics import roc_curve\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# let user feed in 2 parameters, the dataset to mount or download, and the regularization rate of the logistic regression model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser = argparse.ArgumentParser()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser.add_argument(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m--data-folder\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, type=str, dest=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mdata_folder\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, help=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mdata folder mounting point\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser.add_argument(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m--regularization\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, type=float, dest=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, default=0.01, help=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mregularization rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43margs = parser.parse_args()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdata_folder = args.data_folder\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mData folder:\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, data_folder)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Set regularization hyperparameter (passed as an argument to the script)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mreg = args.reg_rate\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Get the experiment run context\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun = Run.get_context()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Separate features and labels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mX, y = dataset[[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mLength\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mDiameter\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mHeight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mWhole weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mShucked weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mViscera weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mShell weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m]].values, dataset[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m].values\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Split data into training set and test set\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Train a logistic regression model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTraining a logistic regression model with regularization rate of\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, reg)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.log(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mRegularization Rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,  np.float(reg))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel = LogisticRegression(C=1/reg, solver=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m).fit(X_train, y_train)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# calculate accuracy\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_hat = model.predict(X_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43macc = np.average(y_hat == y_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAccuracy:\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, acc)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.log(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, np.float(acc))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# calculate AUC\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_scores = model.predict_proba(X_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mauc = roc_auc_score(y_test,y_scores[:,1])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAUC: \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m + str(auc))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mos.makedirs(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, exist_ok=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# note file saved in the outputs folder is automatically uploaded into experiment record\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mjoblib.dump(value=model, filename=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43moutputs/diabetes_model.pkl\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.complete()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magics/osm.py:853\u001b[0m, in \u001b[0;36mOSMagics.writefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    852\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mappend \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    854\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(cell)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '$scripts_1/train.py'"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"id":"qXOHrv4ErM41","outputId":"4239307e-47bc-4aee-997c-c75927eb76bb"}},{"cell_type":"code","source":["# %%writefile $data/abalone_training.py\n","%%writefile \"scripts_1/prepdata/abalone_training.py\"\n","import os\n","import argparse\n","from azureml.core import Run, Dataset\n","import pandas as pd\n","import numpy as np\n","import joblib\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","\n","# Get the script arguments (regularization rate and training dataset ID)\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n","parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n","args = parser.parse_args()\n","\n","# Set regularization hyperparameter (passed as an argument to the script)\n","reg = args.reg_rate\t\n","\n","# Get the experiment run context\n","run = Run.get_context()\n","\n","# Separate features and labels\n","X, y = dataset[['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight']].values, dataset['Age'].values\n","\n","# Split data into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n","\n","# Train a logistic regression model\n","print('Training a logistic regression model with regularization rate of', reg)\n","run.log('Regularization Rate',  np.float(reg))\n","model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n","\n","# calculate accuracy\n","y_hat = model.predict(X_test)\n","acc = np.average(y_hat == y_test)\n","print('Accuracy:', acc)\n","run.log('Accuracy', np.float(acc))\n","\n","# calculate AUC\n","y_scores = model.predict_proba(X_test)\n","auc = roc_auc_score(y_test,y_scores[:,1])\n","print('AUC: ' + str(auc))\n","\n","\n","os.makedirs('outputs', exist_ok=True)\n","# note file saved in the outputs folder is automatically uploaded into experiment record\n","joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n","\n","run.complete()"],"outputs":[{"output_type":"stream","name":"stdout","text":"Writing $data/abalone_training.py\n"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '$data/abalone_training.py'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwritefile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$data/abalone_training.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimport os\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport argparse\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom azureml.core import Run, Dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport pandas as pd\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport numpy as np\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport joblib\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.model_selection import train_test_split\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.linear_model import LogisticRegression\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.metrics import roc_auc_score\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.metrics import roc_curve\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Get the script arguments (regularization rate and training dataset ID)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser = argparse.ArgumentParser()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser.add_argument(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m--regularization\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, type=float, dest=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mreg_rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, default=0.01, help=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mregularization rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparser.add_argument(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--input-data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, type=str, dest=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mtraining_dataset_id\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, help=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mtraining dataset\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43margs = parser.parse_args()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Set regularization hyperparameter (passed as an argument to the script)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mreg = args.reg_rate\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Get the experiment run context\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun = Run.get_context()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Separate features and labels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mX, y = dataset[[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mLength\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mDiameter\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mHeight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mWhole weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mShucked weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mViscera weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mShell weight\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m]].values, dataset[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m].values\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Split data into training set and test set\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# Train a logistic regression model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mTraining a logistic regression model with regularization rate of\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, reg)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.log(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mRegularization Rate\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m,  np.float(reg))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mmodel = LogisticRegression(C=1/reg, solver=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m).fit(X_train, y_train)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# calculate accuracy\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_hat = model.predict(X_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43macc = np.average(y_hat == y_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAccuracy:\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, acc)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.log(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, np.float(acc))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# calculate AUC\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_scores = model.predict_proba(X_test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mauc = roc_auc_score(y_test,y_scores[:,1])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mAUC: \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m + str(auc))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mos.makedirs(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, exist_ok=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# note file saved in the outputs folder is automatically uploaded into experiment record\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mjoblib.dump(value=model, filename=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43moutputs/diabetes_model.pkl\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mrun.complete()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magics/osm.py:853\u001b[0m, in \u001b[0;36mOSMagics.writefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    852\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mappend \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    854\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(cell)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '$data/abalone_training.py'"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1667532114966},"id":"k2x8ntTRrM42","outputId":"f37c6ef7-49d1-4ac7-9ac9-3c447e1308c7"}}],"metadata":{"kernelspec":{"name":"python38-azureml","language":"python","display_name":"Python 3.8 - AzureML"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"python38-azureml"},"microsoft":{"host":{"AzureML":{"notebookHasBeenCompleted":true}}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}